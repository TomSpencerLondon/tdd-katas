Chapter 2 
Principles in Refactoring 
The example in Chapter 1, “Refactoring, a First Example,” should give you a 
good feel for what refactoring is all about. Now it’s time to step back and look 
at the key principles of refactoring and at some of the issues you need to think about in using refactoring. 
Where Did Refactoring Come From? 
I’ve not succeeded in pinning down the real birth of the term refactoring. Good programmers certainly have spent at least some time cleaning up their code. They do this because they have learned that clean code is easier to change than complex and messy code, and good programmers know that they rarely write clean code the first time around. 
Refactoring goes beyond this. In this book I’m advocating refactoring as a 
key element in the whole process of software development. Two of the first people to recognize the importance of refactoring were Ward Cunningham and Kent Beck, who worked with Smalltalk from the 1980s onward. Smalltalk is an environment that even then was particularly hospitable to refactoring. It is a dynamic environment that allows you quickly to write highly functional software. Smalltalk has a short compile-link-execute cycle, which makes it easy to change things quickly. It is also object oriented and thus provides powerful tools for minimizing the impact of change behind well-defined interfaces. Ward and Kent worked hard at developing a software development process geared to working with this kind of environment. (Kent used this style as inspiration for his book eXtreme Programming eXplained [Beck, XP].) They realized that refactoring was important in improving their productivity and ever since have been working with refactoring, applying it to serious software projects, and refining the process. 
Ward and Kent’s ideas have always been a strong influence on the Smalltalk 
community, and the notion of refactoring has become an important element in the Smalltalk culture. Ralph Johnson and Don Roberts, both of the University 
     
  
Chapter 2  Principles in Refactoring 52
Defining
Refactoringof Illinois, were also pioneers in Smalltalk refactoring. Ralph is famous as one 
of the Gang of Four [Gang of Four], and explored how refactoring can help develop an efficient and flexible framework. 
Bill Opdyke was one of Ralph’s doctoral students and is particularly inter-
ested in frameworks. He saw the potential value of refactoring and saw that it could be applied to much more than Smalltalk. His background was in tele-phone switch development, in which a great deal of complexity accrues over time, and changes are difficult to make. Bill’s doctoral research looked at refac-toring from a tool builder’s perspective. Bill investigated the refactorings that would be useful for C++ framework development and researched the necessary semantics-preserving refactorings, how to prove they were semantics preserv-ing, and how a tool could implement these ideas. 
I remember meeting Bill at the OOPSLA conference in 1992. We sat in a café 
and discussed some of the work I’d done in building a conceptual framework for health care. Bill told me about his research, and I remember thinking, “Inter-esting, but not really that important.” Boy was I wrong! 
And me? I’d always been inclined to clean code, but I’d never considered it 
to be that important. Then I worked on a project with Kent and saw the way he used refactoring. I saw the difference it made in productivity and quality. That experience convinced me that refactoring was an important technique. I was frustrated, however, because there was no book that I could give to a working programmer, and none of the experts mentioned previously had any plans to write such a book. So, with their help, we wrote the first edition of Refactor-
ing. Now, with Jay and Shane, we’ve been able to update the book with our learnings over the past nine years and add material that applies to Ruby, and dynamic languages in general. 
Defining Refactoring 
I’m always a little leery of definitions because everyone has his or her own, but when you write a book you get to choose your own definitions. In this case I’m basing my definitions on the work done by Ralph Johnson’s group and assorted associates.
The first thing to say about this is that the word refactoring has two defini-
tions depending on context. You might find this annoying (I certainly do), but it serves as yet another example of the realities of working with natural language. 
The first definition is the noun form. 
     
  
Defining Refactoring 53
Defining
RefactoringTip Refactoring (noun): A change made to the internal structure of 
software to make it easier to understand and cheaper to modify with-
out changing its observable behavior. 
You can find examples of refactorings in the catalog, such as Extract Method 
and Replace Hash with Object. As such, a refactoring is usually a small change to the software, although one refactoring can involve others. For example, Extract Class usually involves Move Method and Move Field. 
The other usage of refactoring is the verb form. 
Tip Refactor (verb): To restructure software by applying a series of 
refactorings without changing its observable behavior. 
So you might spend a few hours refactoring, during which you might apply a 
couple of dozen individual refactorings. 
I’ve been asked, “Is refactoring just cleaning up code?” In a way the answer 
is yes, but I think refactoring goes further because it provides a technique for cleaning up code in a more efficient and controlled manner. Since I’ve been using refactoring, I’ve noticed that I clean code far more effectively than I did before. This is because I know which refactorings to use, I know how to use them in a manner that minimizes bugs, and I test at every possible opportunity. 
I should amplify a couple of points in my definitions. First, the purpose of 
refactoring is to make the software easier to understand and modify. You can make many changes in software that make little or no change in the observ-able behavior. Only changes that make the software easier to understand are refactorings. A good contrast is performance optimization. Like refactoring, performance optimization does not usually change the behavior of a component (other than its speed); it only alters the internal structure. However, the purpose is different. Performance optimization often makes code harder to understand, but you need to do it to get the performance you need. 
The second thing I want to highlight is that refactoring does not change the 
observable behavior of the software. The software still carries out the same function that it did before. Any user, whether an end user or another program-mer, cannot tell that things have changed. 
     
  
Chapter 2  Principles in Refactoring 54
Why Should
You
Refactor?The Two Hats 
This second point leads to Kent Beck’s metaphor of two hats. When you use 
refactoring to develop software, you divide your time between two distinct activ-ities: adding function and refactoring. When you add function, you shouldn’t be changing existing code; you are just adding new capabilities. You can measure your progress by adding tests and getting the tests to work. When you refactor, you make a point of not adding function; you only restructure the code. You don’t add any tests (unless you find a case you missed earlier); you only restruc-ture the code. Additionally, you only change tests when you absolutely need to in order to cope with a change in an interface. 
As you develop software, you probably find yourself swapping hats fre-
quently. You start by trying to add a new function, and you realize this would be much easier if the code were structured differently. So you swap hats and refactor for a while. Once the code is better structured, you swap hats and add the new function. Once you get the new function working, you realize you coded it in a way that’s awkward to understand, so you swap hats again and refactor. All this might take only ten minutes, but during this time you should always be aware of which hat you’re wearing. 
Why Should You Refactor? 
I don’t want to proclaim refactoring as the cure for all software ills. It is no “sil-ver bullet.” Yet it is a valuable tool, a pair of silver pliers that helps you keep a good grip on your code. Refactoring is a tool that can, and should, be used for several purposes. 
Refactoring Improves the Design of Software 
Without refactoring, the design of the program will decay. As people change code—whether changes to realize short-term goals or changes made without a full comprehension of the design of the code—the code loses its structure. It becomes harder to see the design by reading the code. Refactoring is rather like tidying up the code. Work is done to remove bits that aren’t really in the right place. Loss of the structure of code has a cumulative effect. The harder it is to see the design in the code, the harder it is to preserve it, and the more rapidly it decays. Regular refactoring helps code retain its shape. 
Poorly designed code usually takes more code to do the same things, often 
because the code literally does the same thing in several places. Thus an impor-
     
  
Why Should You Refactor? 55
Why Should
You
Refactor?tant aspect of improving design is to eliminate duplicate code. The importance 
of this lies in future modifications to the code. Reducing the amount of code won’t make the system run any faster, because the effect on the footprint of the programs rarely is significant. Reducing the amount of code does, however, make a big difference in modification of the code. The more code there is, the harder it is to modify correctly. There’s more code to understand. You change this bit of code here, but the system doesn’t do what you expect because you didn’t change that bit over there that does much the same thing in a slightly different context. By eliminating the duplicates, you ensure that the code says everything once and only once, which is the essence of good design. 
Refactoring Makes Software Easier to Understand 
Programming is in many ways a conversation with a computer. You write code that tells the computer what to do, and it responds by doing exactly what you tell it. In time you close the gap between what you want it to do and what you tell it to do. Programming in this mode is all about saying exactly what you want. But there is another user of your source code. Someone will try to read your code in a few months’ time to make some changes. We easily forget that extra user of the code, yet that user is actually the most important. Who cares if the computer takes a few more cycles to execute something? It does matter if it takes a programmer a week to make a change that would have taken only an hour if she had understood your code. 
The trouble is that when you are trying to get the program to work, you are 
not thinking about that future developer. It takes a change of rhythm to make changes that make the code easier to understand. Refactoring helps you to make your code more readable. When refactoring you have code that works but is not ideally structured. A little time spent refactoring can make the code better communicate its purpose. Programming in this mode is all about saying exactly what you mean. 
I’m not necessarily being altruistic about this. Often this future developer 
is me. Here refactoring is particularly important. I’m a very lazy programmer. One form of my laziness is that I never remember things about the code I write. Indeed, I deliberately try not remember anything I can look up, because I’m afraid my brain will get full. I make a point of trying to put everything I should remember into the code so I don’t have to remember it. 
This understandability works another way, too. I use refactoring to help me 
understand unfamiliar code. When I look at unfamiliar code, I have to try to understand what it does. I look at a couple of lines and say to myself, oh yes, that’s what this bit of code is doing. With refactoring I don’t stop at the mental 
     
  
Chapter 2  Principles in Refactoring 56
Why Should
You
Refactor?note. I actually change the code to better reflect my understanding, and then I 
test that understanding by rerunning the code to see if it still works. 
Early on I do refactoring like this on little details. As the code gets clearer, 
I find I can see things about the design that I could not see before. Had I not changed the code, I probably never would have seen these things, because I’m just not clever enough to visualize all this in my head. Ralph Johnson describes these early refactorings as wiping the dirt off a window so you can see beyond. When I’m studying code I find refactoring leads me to higher levels of under-standing that otherwise I would miss. 
Refactoring Helps You Find Bugs 
Help in understanding the code also helps me spot bugs. I admit I’m not terri-bly good at finding bugs. Some people can read a lump of code and see bugs; I cannot. However, I find that if I refactor code, I work deeply on understanding what the code does, and I put that new understanding right back into the code. By clarifying the structure of the program, I clarify certain assumptions I’ve made, to the point at which even I can’t avoid spotting the bugs. 
It reminds me of a statement Kent Beck often makes about himself, “I’m not 
a great programmer; I’m just a good programmer with great habits.” Refactor-ing helps me be much more effective at writing robust code. 
Refactoring Helps You Program Faster 
In the end, all the earlier points come down to this: Refactoring helps you develop code more quickly. 
This sounds counterintuitive. When I talk about refactoring, people can eas-
ily see that it improves quality. Improving design, improving readability, reduc-ing bugs, all these improve quality. But doesn’t all this reduce the speed of development?
I strongly believe that a good design is essential for rapid software develop-
ment. Indeed, the whole point of having a good design is to allow rapid devel-opment. Without a good design, you can progress quickly for a while, but soon the poor design starts to slow you down. You spend time finding and fixing bugs instead of adding new function. Changes take longer as you try to under-stand the system and find the duplicate code. New features need more coding as you patch over a patch that patches a patch on the original code base. 
     
  
When Should You Refactor? 57
When 
Should
You
Refactor?A good design is essential to maintaining speed in software development. 
Refactoring helps you develop software more rapidly, because it stops the design 
of the system from decaying. It can even improve a design. 
When Should You Refactor? 
When I talk about refactoring, I’m often asked about how it should be sched-uled. Should we allocate two weeks every couple of months to refactoring? 
In almost all cases, I’m opposed to setting aside time for refactoring. In my 
view refactoring is not an activity you set aside time to do. Refactoring is some-thing you do all the time in little bursts. You don’t decide to refactor, you refac-tor because you want to do something else, and refactoring helps you do that other thing. 
The Rule of Three 
Here’s a guideline Don Roberts gave me: The first time you do something, you just do it. The second time you do something similar, you wince at the duplica-tion, but you do the duplicate thing anyway. The third time you do something similar, you refactor. 
Tip Three strikes and you refactor. 
Refactor When You Add Function 
The most common time to refactor is when I want to add a new feature to some software. Often the first reason to refactor here is to help me understand some code I need to modify. This code may have been written by someone else, or I may have written it. Whenever I have to think to understand what the code is doing, I ask myself if I can refactor the code to make that understanding more immediately apparent. Then I refactor it. This is partly for the next time I pass by here, but mostly it’s because I can understand more things if I clarify the code as I’m going along. 
The other driver of refactoring here is a design that does not help me add a 
feature easily. I look at the design and say to myself, “If only I’d designed the code this way, adding this feature would be easy.” In this case I don’t fret over my past misdeeds—I fix them by refactoring. I do this partly to make future 
     
  
Chapter 2  Principles in Refactoring 58
When 
Should
You
Refactor?enhancements easy, but mostly I do it because I’ve found it’s the fastest way. 
Refactoring is a quick and smooth process. Once I’ve refactored, adding the feature can go much more quickly and smoothly. 
Sometimes a new framework is released or a new technique is found that 
may replace a portion of your application. Developers are often eager to both remove existing pain points and experiment with new solutions. Refactoring when you add function always needs Return on Investment (ROI) consider-ation; however, there is often hidden ROI. For example, replacing a section of your code with a framework means there is less code for the existing team and new members to understand. Of course, this must be weighed against the fact that the framework likely isn’t bulletproof. However, when using a framework you can not only utilize your team to diagnose problems, you can also utilize the community that uses the framework. Another hidden ROI for utilizing new frameworks or ideas is that you may fail when attempting to put it in your code base; however, failure is often as important as success. If you never try the framework (or technique) you will never know where it applies and where it doesn’t. Today’s failure may result in a deeper understanding of the framework that may lead to a great gain in the future when it is utilized in a successful way. 
Refactor When You Need to Fix a Bug 
In fixing bugs much of the use of refactoring comes from making code more understandable. As I look at the code trying to understand it, I refactor to help improve my understanding. Often I find that this active process of working with the code helps in finding the bug. One way to look at it is that if you do get a bug report, it’s a sign you need refactoring, because the code was not clear enough for you to see there was a bug. 
Refactor As You Do a Code Review 
Some organizations do regular code reviews; those that don’t would do better if they did. Code reviews help spread knowledge through a development team. Reviews help more experienced developers pass knowledge to less experienced people. They help more people understand more aspects of a large software system. They are also important in writing clear code. My code may look clear to me but not to my team. That’s inevitable—it’s hard for people to put them-selves in the shoes of someone unfamiliar with the things they are working on. Reviews also give the opportunity for more people to suggest useful ideas. I can only think of so many good ideas in a week. Having other people contribute makes my life easier, so I always look for many reviews. 
     
  
When Should You Refactor? 59
When 
Should
You
Refactor?I’ve found that refactoring helps me review someone else’s code. Before I 
started using refactoring, I could read the code, understand some degree of it, 
and make suggestions. Now when I come up with ideas, I consider whether they can be easily implemented then and there with refactoring. If so, I refactor. When I do it a few times, I can see more clearly what the code looks like with the suggestions in place. I don’t have to imagine what it would be like, I can see what it is like. As a result, I can come up with a second level of ideas that I would never have realized had I not refactored. 
Refactoring also helps the code review have more concrete results. Not only 
are there suggestions, but also many suggestions are implemented there and then. You end up with much more of a sense of accomplishment from the exer-cise.
To make this process work, you have to have small review groups. My expe-
rience suggests having one reviewer and the original author work on the code together. The reviewer suggests changes, and they both decide whether the changes can be easily refactored in. If so, they make the changes. 
With larger design reviews it is often better to obtain several opinions 
in a larger group. Showing code often is not the best device for this. I pre-fer UML diagrams and walking through scenarios with Class-Responsibility-Collaboration (CRC) cards. So I do design reviews with groups and code reviews with individual reviewers. 
This idea of active code review is taken to its limit with the extreme program-
ming [Beck, XP] practice of pair programming. With this technique all serious development is done with two developers at one machine. In effect it’s a con-tinuous code review folded into the development process, and the refactoring that takes place is folded in as well. 
Refactoring for Greater Understanding (aka, Refactor to the 
Same Thing) 
A senior developer once joined a team I was leading, halfway through the proj-
ect. When he joined he saw things that he didn’t agree with and suggested that we refactor the code toward a better domain model. Anxious to learn from the senior developer, I paired with him over the next few days while we made various changes to the domain model. Unfortunately, many of the changes that the senior developer suggested could not be implemented due to additional con-straints imposed by required features. In the end, the code was refactored to be slightly better; however, the largest benefit was the deep understanding that the senior developer gained from the refactoring. From that point forward he deliv-ered value at the level you would expect from a team member who has been on 
     
  
Chapter 2  Principles in Refactoring 60
Why
Refactoring
Worksthe project from day one. The project lost two development days toward new 
features; however, it gained a fully productive senior developer only two days after joining the project. That developer’s contribution in the following months greatly outweighed the original slowdown. 
I see refactoring for greater understanding fairly often; however, I don’t think 
it’s a bad thing. When developers have a deeper understanding of the code base they can be more effective at adding to it and suggesting how to improve it. 
Why Refactoring Works 
Kent Beck 
Programs have two kinds of value: What they can do for you today and what 
they can do for you tomorrow. Most times when programming, we are focused on what we want the program to do today. Whether we are fixing a bug or add-ing a feature, we are making today’s program more valuable by making it more capable.
You can’t program long without realizing that what the system does today 
is only a part of the story. If you can get today’s work done today, but you do it in such a way that you can’t possibly get tomorrow’s work done tomorrow, then you lose. Notice, though, that you know what you need to do today, but you’re not quite sure about tomorrow. Maybe you’ll do this, maybe that, maybe something you haven’t imagined yet. 
I know enough to do today’s work. I don’t know enough to do tomorrow’s. 
But if I only work for today, I won’t be able to work tomorrow at all. 
Refactoring is one way out of the bind. When you find that yesterday’s deci-
sion doesn’t make sense today, you change the decision. Now you can do today’s work. Tomorrow, some of your understanding as of today will seem naive, so you’ll change that, too. 
What makes programs hard to work with? I can think of four things: 
• Programs that are hard to read are hard to modify. • Programs that have duplicated logic are hard to modify. • Programs that require additional behavior that requires you to change run-
ning code are hard to modify. 
• Programs with complex conditional logic are hard to modify. 
     
  
Indirection and Refactoring 61
Indirection
and
RefactoringSo, we want programs that are easy to read, that have all logic specified in 
one and only one place, that do not allow changes to endanger existing behav-
ior, and that allow conditional logic to be expressed as simply as possible. 
Refactoring is the process of taking a running program and adding to its 
value, not by changing its behavior but by giving it more of these qualities that enable us to continue developing at speed. 
What Do I Tell My Manager? 
How to tell a manager about refactoring is one of the most common questions I’ve been asked. If the manager is technically savvy, introducing the subject may not be that hard. If the manager is genuinely quality oriented, then the thing to stress is the quality aspect. Here using refactoring in the review process is a good way to work things. Many studies show that technical reviews are an important way to reduce bugs and thus speed up development. Take a look at any book on reviews, inspections, or the software development process for the latest cita-tions. These should convince most managers of the value of reviews. It is then a short step to introduce refactoring as a way of getting review comments into the code. 
Of course, many people say they are driven by quality but are more driven by 
schedule. In these cases I give my more controversial advice: Don’t tell! 
Subversive? I don’t think so. Software developers are professionals. Our job 
is to build effective software as rapidly as we can. My experience is that refac-toring is a big aid to building software quickly. If I need to add a new function and the design does not suit the change, I find it’s quicker to refactor first and then add the function. If I need to fix a bug, I need to understand how the software works and I find refactoring is the fastest way to do this. A schedule-driven manager wants me to do things the fastest way I can; how I do it is my business. The fastest way is to refactor; therefore I refactor. 
Indirection and Refactoring 
Kent Beck 
Computer science is the discipline that believes all problems can be solved 
with one more layer of indirection. —Dennis DeBruler 
Given software engineers’ infatuation with indirection, it may not surprise 
you to learn that most refactoring introduces more indirection into a program. 
     
  
Chapter 2  Principles in Refactoring 62
Indirection
and
RefactoringRefactoring tends to break big objects and big methods into several smaller 
ones.
Indirection is a two-edged sword, however. Every time you break one thing 
into two pieces, you have more things to manage. It also can make a program harder to read as an object delegates to an object delegating to an object. So you’d like to minimize indirection. 
Not so fast, buddy. Indirection can pay for itself. Here are some of the ways: 
• To enable sharing of logic. For example, a submethod invoked in two dif-
ferent places or a method in a superclass shared by all subclasses. 
• To explain intention and implementation separately. Choosing the name 
of each class and the name of each method gives you an opportunity to 
explain what you intend. The internals of the class or method explain how the intention is realized. If the internals also are written in terms of inten-tion in yet smaller pieces, you can write code that communicates most of the important information about its own structure. 
• To isolate change. I use an object in two different places. I want to change 
the behavior in one of the two cases. If I change the object, I risk changing both. So I first make a subclass and refer to it in the case that is changing. Now I can modify the subclass without risking an inadvertent change to the other case. 
• To encode conditional logic. Objects have a fabulous mechanism, poly-
morphic messages, to flexibly but clearly express conditional logic. By changing explicit conditionals to messages, you can often reduce duplica-tion, add clarity, and increase flexibility all at the same time. 
Here is the refactoring game: Maintaining the current behavior of the system, 
how can you make your system more valuable, either by increasing its quality or by reducing its cost? 
The most common variant of the game is to look at your program. Identify a 
place where it is missing one or more of the benefits of indirection. Put in that indirection without changing the existing behavior. Now you have a more valu-able program because it has more qualities that we will appreciate tomorrow. 
Contrast this with careful up-front design. Speculative design is an attempt 
to put all the good qualities into the system before any code is written. Then the 
code can just be hung on the sturdy skeleton. The problem with this process is 
that it is too easy to guess wrong. With refactoring, you are never in danger of being completely wrong. The program always behaves at the end as it did at the beginning. In addition, you have the opportunity to add valuable qualities to the code. 
     
  
Problems with Refactoring 63
Problems
with
RefactoringThere is a second, rarer refactoring game. Identify indirection that isn’t pay-
ing for itself and take it out. Often this takes the form of intermediate methods 
that used to serve a purpose but no longer do. Or it could be a component that you expected to be shared or polymorphic but turned out to be used in only one place. When you find parasitic indirection, take it out. Again, you will have a more valuable program, not because there is more of one of the four qualities listed earlier but because it costs less indirection to get the same amount from the qualities. 
Problems with Refactoring 
When you learn a new technique that greatly improves your productivity, it is hard to see when it does not apply. Usually you learn it within a specific con-text, often just a single project. It is hard to see what causes the technique to be less effective, even harmful. When writing the original book, refactoring was a relatively new practice, and it was difficult to identify potential problems. Now, refactoring is a mature practice, and we can speak more confidently about the benefits and potential pitfalls. 
Changing Interfaces 
One of the important things about objects is that they allow you to change the implementation of a software module separately from changing the interface. You can safely change the internals of an object without anyone else’s worrying about it, but the interface is important—change that and anything can happen. 
Something disturbing about refactoring is that many of the refactorings do 
change an interface. Something as simple as Rename Method is all about chang-ing an interface. So what does this do to the treasured notion of encapsulation? 
There is no problem changing a method name if you have access to all the 
code that calls that method. Even if the method is public, as long as you can reach and change all the callers, you can rename the method. There is a prob-lem only if the interface is being used by code that you cannot find and change. When this happens, I say that the interface becomes a published interface (a step beyond a public interface). Once you publish an interface, you can no longer safely change it and just edit the callers. You need a somewhat more compli-cated process. 
This notion changes the question. Now the problem is: What do you do 
about refactorings that change published interfaces? 
     
  
Chapter 2  Principles in Refactoring 64
Problems
with
RefactoringIn short, if a refactoring changes a published interface, you have to retain 
both the old interface and the new one, at least until your users have had a 
chance to react to the change. Fortunately, this is not too awkward. You can usually arrange things so that the old interface still works. Try to do this so that the old interface calls the new interface. In this way when you change the name of a method, keep the old one, and just let it call the new one. Don’t copy the method body—that leads you down the path to damnation by way of dupli-cated code. You should also create some type of deprecation facility; that way your callers will know that something is up (See the “Refactor with Depreca-tion” section of “Replace Array with Object” in Chapter 8 for details). 
Protecting interfaces usually is doable, but it is a pain. You have to build and 
maintain these extra methods, at least for a time. The methods complicate the interface, making it harder to use. There is an alternative: Don’t publish the interface. Now I’m not talking about a total ban here, clearly you have to have published interfaces. If you are building APIs for outside consumption, as Sun does, then you have to have published interfaces. I say this because I often see development groups using published interfaces far too much. I’ve seen a team of three people operate in such a way that each person published interfaces to the other two. This led to all sorts of gyrations to maintain interfaces when it would have been easier to go into the code base and make the edits. Organizations with an overly strong notion of code ownership tend to behave this way. Using published interfaces is useful, but it comes with a cost. So don’t publish inter-faces unless you really need to. This may mean modifying your code owner-ship rules to allow people to change other people’s code to support an interface change. Often it is a good idea to do this with pair programming. 
Tip Don’t publish interfaces prematurely. Modify your code owner-
ship policies to smooth refactoring. 
Databases
One problem area for refactoring is databases. Many business applications are tightly coupled to the database schema that support them. That’s one reason that the database is difficult to change. Another reason is data migration. Even if you have carefully layered your system to minimize the dependencies between the database schema and the object model, changing the database schema forces you to migrate the data, which can be a long and fraught task. The addition of a rigorous one-click deployment process with database migrations as part of 
     
  
Problems with Refactoring 65
Problems
with
Refactoringthat process certainly helps. Write your migrations to modify the schema and 
migrate the data. Use temporary tables if you need to preserve the data while you modify the schema. Write tests for your migrations. 
The migration task can still take a very long time, and in some systems regu-
lar modification of the schema may not be feasible. One way to deal with this problem is to place a separate layer of software between your object model and your database model. That way you can isolate the changes to the two different models. As you update one model, you don’t need to update the other. You just update the intermediate layer. Such a layer adds complexity but gives you a lot of flexibility. Even without refactoring it is very important in situations in which you have multiple databases or a complex database model that you don’t have control over. 
You don’t have to start with a separate layer. You can create the layer as you 
notice parts of your object model becoming volatile. This way you get the great-est leverage for your changes. 
For more information on Refactoring databases see Pramod Sadalage and 
Scott Ambler’s book  Refactoring Databases  [Sadalage]. 
Design Changes That Are Difficult to Refactor 
Can you refactor your way out of any design mistake, or are some design deci-sions so central that you cannot count on refactoring to change your mind later? In the vast majority of situations, refactoring will see you through. Certain architectural decisions, such as the choice of framework or choice of integra-tion technology are harder to refactor away from, but certainly possible. In one project we wanted to move to a message-oriented architecture to improve per-formance and decouple components of the system, but the business was reluc-tant to pay for a wholesale change. So when it came time to introduce a new set of features, we implemented them using the message-oriented architecture. We were able to stand up the required infrastructure for these relatively simple features, and as modifications were requested of the old features, we refactored them one-by-one to use the new architecture. It took time, but in the end we were successful, and the business was able to receive new features throughout the entire process. 
That said, choice of framework and integration architecture should not be 
made lightly. But once these decisions are made, proceed forward with confi-dence that by applying refactoring techniques, mistakes made today can easily be reversed tomorrow. As you consider design alternatives, ask yourself how 
difficult it would be to refactor from one design into another. If it seems easy, 
don’t worry too much about the choice, and pick the simplest design, even if 
     
  
Chapter 2  Principles in Refactoring 66
Problems
with
Refactoringit does not cover all the potential requirements. However, if you cannot see a 
simple way to refactor, then put more effort into the design. You should find such situations are in the minority. 
When Shouldn’t You Refactor? 
There are times when you should not refactor at all. The principle example is when you should rewrite from scratch instead. There are times when the exist-ing code is such a mess that although you could refactor it, it would be easier to start from the beginning. This decision is not an easy one to make, and I admit that I don’t really have good guidelines for it. 
A clear sign of the need to rewrite is when the current code just does not 
work. You may discover this only by trying to test it and discovering that the code is so full of bugs that you cannot stabilize it. Remember, code has to work mostly correctly before you refactor. 
A compromise route is to refactor a large piece of software into components 
with strong encapsulation. Then you can make a refactor-versus-rebuild deci-sion for one component at a time. Perform Extract Class and Move Method on coherent pieces of behavior. If the behavior is not tested, write tests for it. 
Another time you should avoid refactoring is when you are close to a dead-
line. At that point the productivity gain from refactoring would appear after the deadline and thus be too late. Ward Cunningham has a good way to think of this. He describes unfinished refactoring as going into debt. Most compa-nies need some debt to function efficiently. However, with debt comes inter-est payments, that is, the extra cost of maintenance and extension caused by overly complex code. You can bear some interest payments, but if the payments become too great, you will be overwhelmed. It is important to manage your debt, paying parts of it off by means of refactoring. 
Other than when you are very close to a deadline, however, you should not 
put off refactoring because you haven’t got time. Experience with several proj-ects has shown that a bout of refactoring results in increased productivity. Not having enough time usually is a sign that you need to do some refactoring. 
The most costly refactoring is refactoring for academic purposes. Refactoring 
for academic purposes is in direct conflict with delivering working software. In your career you will likely find many lines of code that you do not agree with; however, disagreeing with implementation is not a good enough reason to refac-tor code. If the code currently hinders your ability to deliver software (or will in the future), you can refactor, but changing code because you philosophically disagree is simply wrong. 
     
  
Refactoring and Design 67
Refactoring
and
DesignFor example, if you believe that state-based testing is the only way to test, 
that isn’t a good enough reason to alter the existing tests that utilize mocks. 
If those tests become a maintenance problem, that’s another issue, but simply disliking mocks does not give you the right to remove them. Creating a beauti-ful code base should always be a priority; however, creating working software is the number one priority. To make matters worse, when you refactor for aca-demic purposes you do not always improve the quality of the code, thus you don’t increase your ability to deliver new features. 
Slowing delivery generally upsets the business sponsors and project manag-
ers. Refactoring is a good thing and everyone should be on board with it. If you can’t prove to the business and the project manager that a refactoring is worth doing, you might be refactoring for academic purposes. 
Refactoring and Design 
Refactoring has a special role as a complement to design. When I first learned to program, I just wrote the program and muddled my way through it. In time I learned that thinking about the design in advance helped me avoid costly rework, and I got more into this style of up-front design. Many people consider design to be the key piece and programming just mechanics. The analogy is, design is an engineering drawing and code is the construction work. But soft-ware is different from physical machines. It is much more malleable, and it is all about thinking. As Alistair Cockburn, codeveloper of the Agile Manifesto puts it, “With design I can think very fast, but my thinking is full of little holes.” 
One argument is that refactoring can be an alternative to up-front design. 
In this scenario you don’t do any design at all. You just code the first approach that comes into your head, get it working, and then refactor it into shape. Actu-ally, this approach can work. I’ve seen people do this and come out with a well-designed piece of software. Those who support extreme programming [Beck, XP] often are portrayed as advocating this approach. 
Although doing only refactoring does work, it is not the most efficient way 
to work. Even the extreme programmers do some design first. They will try out various ideas with CRC cards or the like until they have a plausible first solu-
tion. Only after generating a plausible first shot will they code and then refactor. 
The point is that refactoring changes the role of up-front design. If you don’t refactor, there is a lot of pressure in getting that up-front design right. The sense is that any changes to the design later are going to be expensive. Thus you put more time and effort into the up-front design to avoid the need for such changes. 
     
  
Chapter 2  Principles in Refactoring 68
Refactoring
and 
DesignWith refactoring the emphasis changes. You still do up-front design, but now 
you don’t try to find the perfect solution. Instead all you want is a reasonable 
solution. You know that as you build the functionality, as you understand more about the problem, you may realize that the best solution is different from the one you originally came up with. With refactoring this is not a problem, for it no longer is expensive to make the changes. 
An important result of this change in emphasis is a greater movement toward 
simplicity of design. Before I used refactoring, I always looked for flexible solu-tions. With any requirement I would wonder how that requirement would change during the life of the system. Because design changes were expensive, I would look to build a design that would stand up to the changes I could foresee. The problem with building a flexible solution is that flexibility costs. Flexible solutions are more complex than simple ones. The resulting software is more difficult to maintain in general, although it is easier to flex in the direction I had in mind. Even there, however, you have to understand how to flex the design. For one or two aspects this is no big deal, but changes occur throughout the sys-tem. Building flexibility in all these places makes the overall system a lot more complex and expensive to maintain. The big frustration, of course, is that all this flexibility is not needed. Some of it is, but it’s impossible to predict which pieces those are. To gain flexibility, you are forced to put in a lot more flexibility than you actually need. 
With refactoring you approach the risks of change differently. You still 
think about potential changes; you still consider flexible solutions. But instead of implementing these flexible solutions, you ask yourself, “How difficult is it going to be to refactor a simple solution into the flexible solution?” If, as happens most of the time, the answer is “pretty easy,” you just implement the simple solution. 
Refactoring can lead to simpler designs without sacrificing flexibility. This 
makes the design process easier and less stressful. Once you have a broad sense of things that refactor easily, you don’t even think of the flexible solutions. You have the confidence to refactor if the time comes. You build the simplest thing that can possibly work. As for the flexible, complex design, most of the time you aren’t going to need it. 
     
  
It Takes A While to Create Nothing 69
It Takes
a While to
Create
NothingIt Takes A While to Create Nothing 
Ron Jeffries 
The Chrysler Comprehensive Compensation pay process was running too 
slowly. Although we were still in development, it began to bother us, because it 
was slowing down the tests. 
Kent Beck, Martin Fowler, and I decided we’d fix it up. While I waited for 
us to get together, I was speculating, on the basis of my extensive knowledge of the system, about what was probably slowing it down. I thought of several pos-sibilities and chatted with folks about the changes that were probably necessary. We came up with some really good ideas about what would make the system go faster. 
Then we measured performance using Kent’s profiler. None of the possibili-
ties I had thought of had anything to do with the problem. Instead, we found that the system was spending half its time creating instances of date. Even more interesting was that all the instances had the same couple of values. 
When we looked at the date-creation logic, we saw some opportunities for 
optimizing how these dates were created. They were all going through a string conversion even though no external inputs were involved. The code was just using string conversion for convenience of typing. Maybe we could optimize that.
Then we looked at how these dates were being used. It turned out that the 
huge bulk of them were all creating instances of date range, an object with a “from date” and a “to date.” Looking around a little more, we realized that most of these date ranges were empty! 
As we worked with date range, we used the convention that any date range 
that ended before it started was empty. It’s a good convention and fits in well 
with how the class works. Soon after we started using this convention, we real-
ized that just creating a date range that starts after it ends wasn’t clear code, so we extracted that behavior into a factory method for empty date ranges. 
We had made that change to make the code clearer, but we received an unex-
pected payoff. We created a constant empty date range and adjusted the fac-tory method to return that object instead of creating it every time. That change doubled the speed of the system, enough for the tests to be bearable. It took us about five minutes. 
I had speculated with various members of the team (Kent and Martin deny 
participating in the speculation) on what was likely wrong with the code we knew very well. We had even sketched some designs for improvements without first measuring what was going on. 
     
  
Chapter 2  Principles in Refactoring 70
Refactoring
and
PerformanceWe were completely wrong. Aside from having a really interesting conversa-
tion, we were doing no good at all. 
The lesson is: Even if you know exactly what is going on in your system, 
measure performance; don’t speculate. You’ll learn something, and nine times 
out of ten, it won’t be that you were right! 
Refactoring and Performance 
A common concern with refactoring is the effect it has on the performance of a program. To make the software easier to understand, you often make changes that will cause the program to run more slowly. This is an important issue. I’m not one of the school of thought that ignores performance in favor of design purity or in hopes of faster hardware. Software has been rejected for being too slow, and faster machines merely move the goalposts. Refactoring certainly will make software go more slowly, but it also makes the software more amenable to performance tuning. The secret to fast software, in all but hard real-time con-texts, is to write tunable software first and then to tune it for sufficient speed. 
I’ve seen three general approaches to writing fast software. The most serious 
of these is time budgeting, used often in hard real-time systems. In this situation, as you decompose the design you give each component a budget for resources—time and footprint. That component must not exceed its budget, although a mechanism for exchanging budgeted times is allowed. Such a mechanism focuses hard attention on hard performance times. It is essential for systems such as heart pacemakers, in which late data is always bad data. This technique is overkill for other kinds of systems, such as the corporate information systems with which I usually work. 
The second approach is the constant attention approach. With this approach 
every programmer, all the time, does whatever he or she can to keep perfor-
mance high. This is a common approach and has intuitive attraction, but it does not work very well. Changes that improve performance usually make the pro-gram harder to work with. This slows development. This would be a cost worth paying if the resulting software were quicker, but usually it is not. The perfor-mance improvements are spread all around the program, and each improvement is made with a narrow perspective of the program’s behavior. 
The interesting thing about performance is that if you analyze most pro-
grams, you find that they waste most of their time in a small fraction of the 
code. If you optimize all the code equally, you end up with 90 percent of the optimizations wasted, because you are optimizing code that isn’t run much. The 
     
  
Optimizing a Payroll System 71
Optimizing 
a Payroll
Systemtime spent making the program fast, the time lost because of lack of clarity, is 
all wasted time. 
The third approach to performance improvement takes advantage of this 90 
percent statistic. In this approach you build your program in a well-factored manner without paying attention to performance until you begin a performance optimization stage, usually fairly late in development. During the performance optimization stage, you follow a specific process to tune the program. 
You begin by running the program under a profiler that monitors the pro-
gram and tells you where it is consuming time and space. This way you can find that small part of the program where the performance hot spots lie. Then you focus on those performance hot spots and use the same optimizations you would use if you were using the constant attention approach. But because you are focusing your attention on a hot spot, you are having much more effect for less work. Even so you remain cautious. As in refactoring you make the changes in small steps. After each step you test and rerun the profiler. If you haven’t improved performance, you back out the change. You continue the process of finding and removing hot spots until you get the performance that satisfies your users. McConnel [McConnel] gives more information on this technique in his book Code Complete: A Practical Handbook of Software Construction. 
Having a well-factored program helps with this style of optimization in two 
ways. First, it gives you time to spend on performance tuning. Because you have well-factored code, you can add function more quickly. This gives you more time to focus on performance. (Profiling ensures you focus that time on the right place.) Second, with a well-factored program you have finer granularity for your performance analysis. Your profiler leads you to smaller parts of the code, which are easier to tune. Because the code is clearer, you have a better understanding of your options and of what kind of tuning will work. 
I’ve found that refactoring helps me write fast software. It slows the software 
in the short term while I’m refactoring, but it makes the software easier to tune during optimization. I end up well ahead. 
Optimizing a Payroll System 
Rich Garzaniti 
We had been developing the Chrysler Comprehensive Compensation System 
for quite a while before we started to move it to GemStone. Naturally, when we did that, we found that the program wasn’t fast enough. We brought in Jim Haungs, a master GemSmith, to help us optimize the system. 
     
  
Chapter 2  Principles in Refactoring 72
Optimizing 
a Payroll
SystemAfter a little time with the team to learn how the system worked, Jim used 
GemStone’s ProfMonitor feature to write a profiling tool that plugged into our 
functional tests. The tool displayed the numbers of objects that were being cre-ated and where they were being created. 
To our surprise, the biggest offender turned out to be the creation of strings. 
The biggest of the big was repeated creation of 12,000-byte strings. This was a particular problem because the string was so big that GemStone’s usual gar-bage-collection facilities wouldn’t deal with it. Because of the size, GemStone was paging the string to disk every time it was created. It turned out the strings were being built way down in our IO framework, and they were being built three at a time for every output record! 
Our first fix was to cache a single 12,000-byte string, which solved most of 
the problem. Later, we changed the framework to write directly to a file stream, which eliminated the creation of even the one string. 
Once the huge string was out of the way, Jim’s profiler found similar prob-
lems with some smaller strings: 800 bytes, 500 bytes, and so on. Converting these to use the file stream facility solved them as well. 
With these techniques we steadily improved the performance of the system. 
During development it looked like it would take more than 1,000 hours to run the payroll. When we actually got ready to start, it took 40 hours. After a month we got it down to around 18; when we launched we were at 12. After a year of running and enhancing the system for a new group of employees, it was down to 9 hours. 
Our biggest improvement was to run the program in multiple threads on a 
multiprocessor machine. The system wasn’t designed with threads in mind, but because it was so well factored, it took us only three days to run in multiple threads. Now the payroll takes a couple of hours to run. 
Before Jim provided a tool that measured the system in actual operation, we 
had good ideas about what was wrong. But it was a long time before our good ideas were the ones that needed to be implemented. The real measurements pointed in a different direction and made a much bigger difference. 
     
  
73